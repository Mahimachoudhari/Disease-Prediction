# -*- coding: utf-8 -*-
"""Copy of Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ii4o07Ziwm4_vAvO9Bti_kwucDulh7hi
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans, AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve
)
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv('/content/ml model.zip')

df.head()
df.shape
df.info()
df.describe()

df[['systolic_bp', 'diastolic_bp']] = df['blood_pressure'].str.split('/', expand=True).astype(int)
df.drop('blood_pressure', axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['smoking_habit'] = le.fit_transform(df['smoking_habit'])
df['symptom_1'] = le.fit_transform(df['symptom_1'])
df['symptom_2'] = le.fit_transform(df['symptom_2'])
df['symptom_3'] = le.fit_transform(df['symptom_3'])

#select features
features = [
    'age', 'weight', 'glucose_level', 'insulin_level',
    'systolic_bp', 'diastolic_bp', 'smoking_habit'
]

X = df[features]

#feature scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#K-means
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled)

#visualize clusters
import seaborn as sns
sns.scatterplot(
    x=df['age'],
    y=df['glucose_level'],
    hue=df['Cluster'],
    palette='Set1'
)
plt.title("Patient Clusters")
plt.show()

#cluster analysis
df.groupby('Cluster')[features].mean()

#checking risk level
risk_map = {
    0: "Low Risk",
    1: "Medium Risk",
    2: "High Risk"
}

df['Risk_Level'] = df['Cluster'].map(risk_map)

#weight distri
sns.histplot(df['weight'], bins=20, kde=True)
plt.title("Weight Distribution")
plt.show()



#smoking habit vs diseases
sns.countplot(x='smoking_habit', hue='disease', data=df)
plt.title("Smoking Habit vs Disease")
plt.show()

#blood pressure analysis
sns.scatterplot(
    x='systolic_bp',
    y='diastolic_bp',
    hue='disease',
    data=df
)
plt.title("Blood Pressure vs Disease")
plt.show()

sns.countplot(x='symptom_1', hue='disease', data=df)
plt.show()

sns.countplot(x='symptom_2', hue='disease', data=df)
plt.show()

sns.countplot(x='symptom_3', hue='disease', data=df)
plt.show()

plt.figure(figsize=(10,6))
sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

X = df.drop(['disease', 'Risk_Level'], axis=1)
y = df['disease']

#Encode Categorical Columns
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
categorical_cols = ['smoking_habit', 'symptom_1', 'symptom_2', 'symptom_3']
for col in categorical_cols:
    X[col] = le.fit_transform(X[col])

#train test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

#feature scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#logistic regression
from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

y_pred_lr = lr_model.predict(X_test)

#random forest
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

#model evaluation
from sklearn.metrics import accuracy_score

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

#classification
from sklearn.metrics import classification_report

print("Logistic Regression Report:\n", classification_report(y_test, y_pred_lr))
print("Random Forest Report:\n", classification_report(y_test, y_pred_rf))

#confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred_rf)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix â€“ Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

#ROC curve
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np
classes = np.unique(y_test)
y_test_bin = label_binarize(y_test, classes=classes)
y_prob = rf_model.predict_proba(X_test)
fpr = {}
tpr = {}
for i in range(len(classes)):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
auc = roc_auc_score(
    y_test_bin,
    y_prob,
    multi_class='ovr',
    average='macro'
)

plt.figure(figsize=(7,6))

for i in range(len(classes)):
    plt.plot(fpr[i], tpr[i], label=f"Class {classes[i]}")

plt.plot([0,1], [0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(f"Multiclass ROC Curve (AUC = {auc:.2f})")
plt.legend()
plt.show()

#Diseases prediction of new patient
feature_names = X.columns.tolist()

new_patient = pd.DataFrame([{
    'age': 45,
    'weight': 70,
    'glucose_level': 160,
    'insulin_level': 85,
    'systolic_bp': 140,
    'diastolic_bp': 90,
    'smoking_habit': 1,
    'symptom_1': 1,
    'symptom_2': 0,
    'symptom_3': 1,
    'Cluster': 0   # REQUIRED if used during training
}])

new_patient = new_patient[feature_names]

new_patient_scaled = scaler.transform(new_patient)
prediction = rf_model.predict(new_patient_scaled)

print("Disease Prediction:", "Yes" if prediction[0] == 1 else "NO")